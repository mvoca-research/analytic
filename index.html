<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MVoca Research - Analytics</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f9;
            color: #333;
        }
        header {
            background-color: #4CAF50;
            color: white;
            padding: 1rem;
            text-align: center;
        }
        header h1 {
            margin: 0;
        }
        header p {
            margin: 0.5rem 0 0;
        }
        main {
            padding: 1rem;
        }
        .repo-list {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 1rem;
        }
        .repo {
            background: white;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 1rem;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }
        .repo h2 {
            font-size: 1.5rem;
            margin: 0;
        }
        .repo p {
            margin: 0.5rem 0;
            font-size: 0.9rem;
            color: #666;
        }
        footer {
            background-color: #333;
            color: white;
            text-align: center;
            padding: 1rem 0;
            margin-top: 2rem;
        }
        footer a {
            color: #4CAF50;
            text-decoration: none;
        }
    </style>
</head>
<body>
    <header>
        <h1>MVoca Research - Analytics</h1>
        <p>Exploring analytics and innovation in research.</p>
    </header>
    <main>
        <h2>Our Repositories</h2>
        <div class="repo-list">
            <div class="repo">
                <h2><a href="https://github.com/mvoca-research/Llama-3.2-11B-Vision-Instruct" target="_blank">Llama-3.2-11B-Vision-Instruct</a></h2>
                <p>Llama 3.2 11B Vision Instruct model is part of Meta's latest series of large language models that introduce significant advancements in multimodal AI capabilities, allowing for both text and image inputs.</p>
                <p><strong>Language:</strong> Python</p>
            </div>
            <div class="repo">
                <h2><a href="https://github.com/mvoca-research/inferless-onboarding" target="_blank">inferless-onboarding</a></h2>
                <p>GPT-Neo 125M is a transformer model designed using EleutherAI's replication of the GPT-3 architecture. GPT-Neo refers to the class of models, while 125M represents the number of parameters of this particular pre-trained model.</p>
                <p><strong>Language:</strong> Python</p>
            </div>
        </div>
    </main>
    <footer>
        <p>&copy; 2025 MVOCA Research. All Rights Reserved. | <a href="https://github.com/mvoca-research">GitHub</a></p>
    </footer>
</body>
</html>
